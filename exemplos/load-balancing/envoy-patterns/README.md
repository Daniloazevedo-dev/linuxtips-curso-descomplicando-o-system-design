# Load Balancer vs Reverse Proxy Patterns com Envoy

Este exemplo demonstra como uma mesma tecnologia (Envoy) pode implementar tanto o pattern de **Load Balancer** quanto o pattern de **Reverse Proxy**, mostrando claramente a diferenÃ§a conceitual entre eles.

## Objetivo Educacional

Demonstrar que tecnologias como Envoy, NGINX, HAProxy, etc. sÃ£o **ferramentas** que podem implementar diferentes **patterns arquiteturais**:

- **Reverse Proxy Pattern**: Atua como intermediÃ¡rio entre cliente e um Ãºnico serviÃ§o backend
- **Load Balancer Pattern**: Distribui requisiÃ§Ãµes entre mÃºltiplos backends para balanceamento de carga

## ğŸ—ï¸ Arquitetura do Exemplo

```
[Cliente] 
    â†“
[Load Balancer - Envoy] (Pattern: Load Balancer)
    â†“ (Round Robin)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Reverse Proxy 1] â† [Reverse Proxy 2] â† [Reverse Proxy 3] â”‚ (Pattern: Reverse Proxy)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ â†“ â†“ (todos apontam para o mesmo backend)
[Backend Application - Node.js]
```

### Componentes

1. **1x Backend Application (Node.js)**: A aplicaÃ§Ã£o final que serve as requisiÃ§Ãµes
2. **3x Reverse Proxies (Envoy)**: Cada um atua como proxy reverso para a mesma aplicaÃ§Ã£o
3. **1x Load Balancer (Envoy)**: Distribui o trÃ¡fego entre os 3 reverse proxies

## ğŸ“Š DiferenÃ§as Conceituais

### Reverse Proxy Pattern
- **FunÃ§Ã£o**: IntermediÃ¡rio transparente entre cliente e servidor
- **Objetivo**: 
  - Terminar SSL/TLS
  - Cache de respostas
  - CompressÃ£o
  - AutenticaÃ§Ã£o/AutorizaÃ§Ã£o
  - Mascarar a infraestrutura interna
- **RelaÃ§Ã£o**: 1 proxy â†’ 1 (ou poucos) backend(s)
- **No exemplo**: Cada Envoy proxy reverso aponta para o mesmo backend

### Load Balancer Pattern
- **FunÃ§Ã£o**: Distribuidor de carga entre mÃºltiplos backends
- **Objetivo**:
  - Distribuir requisiÃ§Ãµes
  - Alta disponibilidade
  - Escalabilidade horizontal
  - Health checking
- **RelaÃ§Ã£o**: 1 load balancer â†’ N backends
- **No exemplo**: O Envoy load balancer distribui entre os 3 proxies reversos

## ğŸš€ Como Executar

### PrÃ©-requisitos
- Docker e Docker Compose instalados
- Portas disponÃ­veis: 80, 8081-8083, 9900-9903

### Executar o exemplo

```bash
# Clonar/navegar para o diretÃ³rio
cd envoy-patterns

# Construir e iniciar todos os serviÃ§os
docker-compose up --build

# Ou em background
docker-compose up --build -d
```

### Acessar os serviÃ§os

```bash
# AtravÃ©s do Load Balancer (porta 80)
curl http://localhost/

# Acessar diretamente cada Reverse Proxy
curl http://localhost:8081/  # Reverse Proxy 1
curl http://localhost:8082/  # Reverse Proxy 2
curl http://localhost:8083/  # Reverse Proxy 3

# Endpoints da aplicaÃ§Ã£o
curl http://localhost/api/data
curl http://localhost/health
```

## ğŸ” Observando os Patterns

### 1. Testando o Load Balancer Pattern

```bash
# FaÃ§a vÃ¡rias requisiÃ§Ãµes para ver o balanceamento
for i in {1..900}; do
  echo "RequisiÃ§Ã£o $i:"
  curl -sI 0.0.0.0:80/api/data | grep x-proxy-server
  sleep 1;
done
```

**Resultado esperado**: VocÃª verÃ¡ que as requisiÃ§Ãµes sÃ£o distribuÃ­das entre `reverse-proxy-1`, `reverse-proxy-2`, e `reverse-proxy-3` em round-robin.

### 2. Verificando os Headers de IdentificaÃ§Ã£o

```bash
curl -v http://localhost/
```

**Headers importantes**:
- `X-Load-Balancer: envoy-lb` - Identifica que passou pelo load balancer
- `X-Proxy-Server: reverse-proxy-X` - Identifica qual proxy reverso atendeu
- `X-Pattern: Load-Balancer` - Pattern implementado pelo ponto de entrada
- `X-Proxy-Type: Reverse-Proxy` - Pattern implementado pelos proxies internos


## Simulando Carga

```bash
# Script para simular carga e observar distribuiÃ§Ã£o
for i in {1..20}; do
  response=$(curl -s http://localhost:80/api/data)
  proxy=$(echo $response | jq -r '.service')
  echo "RequisiÃ§Ã£o $i: Atendida por $proxy"
  sleep 0.5
done
```

## ConfiguraÃ§Ãµes Importantes

### Load Balancer (load-balancer.yaml)
```yaml
# Tipo de cluster para mÃºltiplos endpoints
type: STRICT_DNS  # Permite mÃºltiplos endpoints

# Algoritmo de balanceamento
lb_policy: ROUND_ROBIN

# ConfiguraÃ§Ã£o de Weighted Round Robin (Quantum)
endpoints:
  - reverse-proxy-1:8080
    load_balancing_weight: 3  # Recebe 3 requisiÃ§Ãµes por ciclo
  - reverse-proxy-2:8080
    load_balancing_weight: 2  # Recebe 2 requisiÃ§Ãµes por ciclo  
  - reverse-proxy-3:8080
    load_balancing_weight: 1  # Recebe 1 requisiÃ§Ã£o por ciclo

# ConfiguraÃ§Ã£o de Slow Start (ramp-up gradual)
slow_start_config:
  slow_start_window: 60s
```

### ğŸ›ï¸ ConfiguraÃ§Ã£o de Quantum/Weighted Round Robin

O Envoy permite configurar o "quantum" do Round Robin atravÃ©s de diferentes mecanismos:

#### 1. **Load Balancing Weight** (Peso por endpoint)
```yaml
load_balancing_weight: 3  # Este endpoint receberÃ¡ 3x mais trÃ¡fego
```

#### 2. **Slow Start Configuration** (Ramp-up gradual)
```yaml
slow_start_config:
  slow_start_window: 60s  # Janela de 60s para entrada gradual
```

#### 3. **Exemplo de DistribuiÃ§Ã£o Weighted**
Com pesos `[5, 3, 2]`, o padrÃ£o de distribuiÃ§Ã£o serÃ¡:
- **Proxy 1**: 5 requisiÃ§Ãµes (50% do trÃ¡fego)
- **Proxy 2**: 3 requisiÃ§Ãµes (30% do trÃ¡fego)  
- **Proxy 3**: 2 requisiÃ§Ãµes (20% do trÃ¡fego)

**PadrÃ£o de distribuiÃ§Ã£o**: 1-1-1-1-1-2-2-2-3-3 (em um ciclo de 10 requisiÃ§Ãµes)

#### 4. **Testando Weighted Round Robin**
```bash
# Use a configuraÃ§Ã£o weighted
docker-compose -f docker-compose-weighted.yml up

# Observe a distribuiÃ§Ã£o desproporcional
for i in {1..15}; do
  echo "RequisiÃ§Ã£o $i:"
  curl -sI localhost/api/data | grep x-proxy-server
  sleep 0.5
done
```

### Reverse Proxy (reverse-proxy-*.yaml)
```yaml
# Tipo de cluster para endpoint Ãºnico
type: LOGICAL_DNS  # Ideal para um Ãºnico endpoint

# Um Ãºnico endpoint (o backend)
endpoints:
  - backend-app:3000
```


### ExercÃ­cios Propostos

1. Altere o algoritmo de load balancing para `LEAST_REQUEST`
2. Adicione mais instÃ¢ncias de backend e observe o comportamento
3. Simule falha em um dos reverse proxies e observe o health checking
4. Implemente rate limiting no load balancer
5. Configure cache no reverse proxy
